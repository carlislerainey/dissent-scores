{
  "hash": "d038f4b7d131033009876801973ea1b1",
  "result": {
    "markdown": "---\ntitle: \"Get the Raw Data\"\nfreeze: true\n---\n\n\nWe need several data sets for this project.\n\n1.  The IDEA events data ([King and Lowe 2003](https://doi.org/10.7910/DVN/BTMQA0)) from Dataverse. These files are very large and there are several.\n2.  The `states2016.csv` and `system2016.csv` State System Membership data sets from the Correlates of War that we use to define the country-years.\n\n## The IDEA Events Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# load packages\nlibrary(tidyverse)\nlibrary(dataverse)\nlibrary(httr)\n\n# options\noptions(timeout = max(10*60, getOption(\"timeout\")))\n\n## Note: see https://github.com/IQSS/dataverse-client-r/issues/17 and \n## https://github.com/IQSS/dataverse/issues/4373 for a couple of wierd\n## issues with this particular dataverse repo. I think for some reason\n## this breaks the dataverse::get_data() function\n\n# set up \nSys.setenv(\"DATAVERSE_SERVER\" = \"dataverse.harvard.edu\")\ndataset <- get_dataset(\"hdl:1902.1/FYXLAWZRIA\")\ndataset$files[c(\"filename\", \"contentType\")]\n\n# files to download from dataverse\nfilenames <- c(\"Sectors of Source _ Target.txt\", \n               \"Levels of Source _ Target.txt\",\n               \"Names of Source _ Target.txt\",\n               \"1990-1994 Data (N=2_679_938).tab\",\n               \"1995-1999 Data (N=4_108_102)\",\n               \"2000-2004 Data (N=3464898).tab\")\n# create a data frame with filenames and associated ids\nfilenames_df <- dataset$files[, c(\"label\", \"id\")] %>%\n  rename(filename = label) %>%\n  filter(filename %in% filenames) %>%\n  mutate(download_url = paste0(\"https://dataverse.harvard.edu/api/access/datafile/\", id)) %>%\n  glimpse()\n\n# make the filenames compatible with make\nfilenames_df$clean_filename <- filenames_df$filename %>%\n  # convert to lower case\n  str_to_lower() %>%\n  # replace spaces with dashes\n  str_replace_all(\" \", \"-\") %>%\n  # remove any extensions (the raw data have .tab, .txt, and missing extensions)\n  str_remove(\"\\\\.[:alnum:]*\") %>%\n  # add a common.txt extension\n  str_c(\".txt\") %>%\n  # quick look\n  glimpse()\n\n# set directory to save files; create if nec\ndir <- \"data/king-lowe-2008/\"\nif (!dir.exists(dir)) dir.create(dir)\n\n# download and write each file\nfor (i in 1:length(filenames)) {\n  cat(paste0(\"Working on \",filenames_df$filename[i]))\n  # -?- # doesn't work: file <- get_file(filenames[i], \"hdl:1902.1/FYXLAWZRIA\", format = \"original\")\n  # -?- # not need bc above doesn't work: writeBin(file, paste0(dir, clean_filenames[i]))\n  # -?- # see here for more https://github.com/IQSS/dataverse/issues/4373\n  download.file(url = filenames_df$download_url[i], paste0(dir, filenames_df$clean_filename[i]))\n}\n```\n:::\n\n\n## The State System Membership\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# states2016.csv\nread_csv(\"https://correlatesofwar.org/wp-content/uploads/states2016.csv\") %>%\n  write_csv(\"data/states2016.csv\")\n\n# system2016.csv\nread_csv(\"https://correlatesofwar.org/wp-content/uploads/system2016.csv\") %>%\n  write_csv(\"data/system2016.csv\")\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}